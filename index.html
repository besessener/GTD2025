<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>GTD2025</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/black.css">
	<link rel="stylesheet" href="plugin/pointer/pointer.css" />

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<h2>Wenn Performancetest-Tools unter ihrer eigenen Last zusammenbrechen</h2>
				<p><img src="images/cover.png" style="width:40%"></p>
				<aside class="notes">
					Vielleicht seid ihr etwas Ã¼berrascht Ã¼ber den Redner und das Thema. Ich habe gestern Nachmittag erfahren,
					dass ich als Ersatz einspringen kann. Und hier bin ich nun und freue mich, dass einige von euch hier sind, 
					um den Vortrag "Wenn Performancetest-Tools unter ihrer eigenen Last zusammenbrechen" zu hÃ¶ren.
					Die Vorbereitungszeit war jetzt nicht all zu lang. Ich versuche deswegen auch mehr auf praktische Erfahrungen einzugehen,
					statt es zu theoretisch zu gestalten. Angereichert mit der ein oder anderen Anekdote.
				</aside>
			</section>
			<section>
				<h2>Agenda ğŸ“‹</h2>
				<ul>
					<li>kurze Vorstellung</li>
					<li>Testobjekt</li>
					<li>Performance-Testing</li>
					<li>Apache JMeter</li>
					<li>Test Setup & DurchfÃ¼hrung</li>
					<li>Ergebnisse</li>
					<li>Fazit</li>
				</ul>
			</section>
			<section>
				<h2>Der Sprecher ğŸ™Š</h2><img src="images/matthias.png" class="r-stretch">
				<p>Matthias Eggert</p>
				<aside class="notes">
					Ich bin Matthias Eggert, 37 Jahre hier aus Frankfurt. Ich bin mittlerweile 12 Jahre professionell in der Softwareentwicklung tÃ¤tig.
					Davon war ich 10 Jahre in der Automobilindustrie, hier bei Conti in Frankfurt RÃ¶delheim und habe mich dort mit
					Developer-Plattformen beschÃ¤ftigt. Das heiÃŸt, ich habe Software fÃ¼r Softwareentwickler entwickelt.
					Im Laufe der Zeit habe ich mich auf CI/CD und DevOps spezialisiert. Aus meiner DevOps-Rolle heraus bin ich dann bei
					Qytera gelandet, wo ich fÃ¼r Testautomatisierung, insbesondere von Performancetests zustÃ¤ndig bin.
				</aside>
			</section>
			<section>
				<section>
					<h2>Testobjekt ğŸ§«</h2>
					<aside class="notes">
						Lasst uns doch direkt mal anschauen was eigentlich getestet wurde. Denn ohne das Testobjekt ist es
						ja auch schwer zu sagen, was wie warum getestet wurde.
					</aside>
				</section>
				<section>
					<h2>Demokratischer Prozess ğŸ—½</h2>
					<ul>
						<li>Viele Millionen Menschen, Dienste und Crawler</li>
						<li>7-stellige Zahl von Requests pro Minute</li>
						<li>Und zwar in der Regel genau an einem Tag</li>
						<li>Auf unterschiedliche Endpunkte</li>
						<li>GroÃŸe Responses</li>
					</ul>
					<aside class="notes">
						Es handelt sich um eine Webanwendung mit mehreren REST Schnittstellen, die Ã¶ffentlich zugÃ¤nglich ist.
						Die Webanwendung selbst ist fÃ¼r einen demokratischen Prozess zustÃ¤ndig, bei dem Millionen von Menschen
						und Diensten drauf zugreifen. Dabei reden fÃ¼r von mehreren zehn millionen Zugriffen pro Minute.
						Das ganze passiert in der Regel an einem Tag. Nicht davor und nicht dannach. In der Regel ist das bei uns ein Sonntag. 
						Die Anfragen gehen natÃ¼rlich auf verschiedene Endpunkte. JSON Antworten und auch Dateiexporte.
					</aside>
				</section>
				<section data-background-color="white">
					<img src="images/halber-donut.png" class="r-stretch">
					<aside class="notes">
						Ich denke damit ist der krypische Teil der ErklÃ¤rungen vorbei. Es geht um die Ergebnissanzeige der 
						Kommunahl- und Europawahlen 2024. Es handelte sich hierbei um einen behÃ¶rdlichen Auftrag, im Vorfeld
						zu den Wahlen die utzerlast entsprechend zu simulieren.
						Ich muss mich hier entschudligen. Hier ist ein bischen viel gelb zu sehen.
						 Die Grafik hab ich Ende November letzten Jahres bereits generieren lassen. Also durch ChatGPT. 
						 Und ChatGPT war in dem Moment noch nicht aktuell genug, und wusste nicht, dass die liberalen sich bereits selbst zerstÃ¶rt hatten.
					</aside>
				</section>
				<section data-background-color="white">
					<img src="images/donuts.png" class="r-stretch">
					<aside class="notes">
						Aber zurÃ¼ck zu den Wahlen. Wichtig dabei war, dass ein besonders hohes Wahlinteresse prognostiziert wurde. viele politische Turbulenzen, die wir alle kennen.
						Dazu natÃ¼rlich der Umstand, dass mehrere BundeslÃ¤nder parallel Kommunahlwahlen abhalten wÃ¤hrend ganz Europa noch wÃ¤hlt.
					</aside>
				</section>
				<section>
					<h2>ZurÃ¼ck zum Testobjekt ğŸ—½</h2>
					<ul>
						<li>Viele Millionen Menschen, Dienste und Crawler</li>
						<li>7-stellige Zahl von Requests pro Minute</li>
						<li>Und zwar in der Regel genau an einem Tag</li>
						<li>Auf unterschiedliche Endpunkte</li>
						<li>GroÃŸe Responses</li>
						<li>DDoS</li>
						<li>Angriffe aus dem Ausland</li>
					</ul>
					<aside class="notes">
						Jetzt muss man also sicherstellen, dass das System einen so groÃŸen Nutzerandrang standhalten kann, gleichzeitig aber 
						gegen DDos-Angriffe und mÃ¶gliche Angriffe eines potentiellen Schurkenstaatees aus dem Ausland gewappnet ist.
						Aber schwenken wir mal rÃ¼ber zu Performance testing.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Performance-Testing â±ï¸</h2>
				</section>
				<section>
					<img src="images/chuck.png" alt="Chuck Norris" class="r-stretch">
					<h1 class="fragment">ğŸ’©</h1>
					<aside class="notes">
						NatÃ¼rlich kÃ¶nnte man jetzt sagen: "ach hat letzte mal geklappt, die paar mehr User die schaffen wir auch dieses mal". 
						frei nach dem Motto, testing is for wimps, ral men test in production. Kann man so machen, aber ist dann eben kacke. 
						Aber wir sind ja Tester, wir sind keine "echten kerle". Der gemeine Tester ist ja GrundsÃ¤tzlich
						Ã¤ngstlich und skeptisch. zu recht.
						Man stelle sich nur die Bild Schlagzeile vor: "Demokratie offline â€“ Kein Signal am Wahltag", "Ampel-Koalition steht auf Rot â€“ Wahlergebnisse im Blindflug" oder "Digitalisierung made in Germany".
						Nein wir sind wimps, wir wollen testen. was denn genau?
					</aside>
				</section>
				<section>
					<h2>Performance-Testing Arten ğŸ‹ï¸ğŸ§˜ğŸš£ğŸƒ</h2>
					<img src="images/performance-tests-types.png" alt="Performance-Testing Arten" class="r-stretch">
					<aside class="notes">
						Performance-Tests umfassen verschiedene Testarten, darunter Lasttests, Stress-Tests und
						Ausdauer- oder Dauertests. Jede dieser Testarten zielt darauf ab, unterschiedliche
						Leistungsaspekte einer Anwendung zu bewerten. Zum Beispiel:

						- Lasttests simulieren eine typische Nutzerbelastung, um zu sehen, wie die Anwendung unter
						normalen Bedingungen funktioniert.
						- Stress-Tests erhÃ¶hen die Belastung schrittweise Ã¼ber das normale Niveau hinaus, um die Grenzen
						der Anwendung zu finden.
						- KapazitÃ¤ts-Tests gehen mit Absicht Ã¼ber die Grenzen der Anwendung hinaus, um zu sehen, wie sie
						scheitert.
						- Ausdauer-Tests prÃ¼fen die Anwendung auf ihre FÃ¤higkeit, Ã¼ber einen langen Zeitraum unter
						erwarteter Belastung zuverlÃ¤ssig zu funktionieren.

						Durch Performance-Tests kÃ¶nnen wir EngpÃ¤sse identifizieren, die Leistung optimieren und
						sicherstellen, dass unsere Anwendung auch unter Spitzenlast oder bei steigender Nutzerzahl
						zuverlÃ¤ssig funktioniert. Mit diesem grundlegenden VerstÃ¤ndnis von Performance-Tests kÃ¶nnen wir
						nun einen spezifischeren Blick auf Apache JMeter werfen und verstehen, wie es uns unterstÃ¼tzt,
						unsere Anwendungen zu testen.
					</aside>
				</section>
				<section>
					<h2>Auto-Scaling What ğŸš—ğŸ¤”â“</h2>
					<img src="images/cloud.webp" class="r-stretch">
					<aside class="notes">
						Es gÃ¤be ja noch tests wie Spike-Testing oder deutsch Lastspitzentests. Oder auch Skalierungstests. 
						Die wÃ¤ren durchaus wichtig wenn wir uns in einem dynamischen Umfeld bewegen wÃ¼rden wo die Nutzerzahlen stÃ¤ndig schwanken.
						Aber in unserem Fall ist das nicht so. Wir haben eine groÃŸe Last an einem Tag, und dann ist es wieder ruhig.
						Entsprechend ist unser Testobjekt auch konstant groÃŸ dimensioniert. Es gibt kein Auto Scaling. Das ist ganz einfach Ã¼berflÃ¼ssig.
					</aside>
				</section>
				<section>
					<h2>Konstante Hochlast â†—ï¸</h2>
					<img src="images/hochlast.png" alt="Performance-Testing Arten" class="r-stretch">
					<aside class="notes">
						Und weil das eben so ist, brauchen wir auch nur eine extrem hohe aber konstante Last zu erzeugen. Und das haben wior gemacht. 
						und zwar mit apache jmeter. in unserer eigenen kleinen Umgebung Namens Qload. Das hilft und Lastagenten in der Cloud zu erzeugen.
						Ich werde im folgenden allerdings eher auf die technischen details eingehen, wie man sowas umsetzen kann, als hieraus eine Werbeveranstaltung werden zu lassen.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<section>
						<h2>Apache JMeter ğŸª¶</h2>
						<ul>
							<li><b>Open Source</b></li>
							<li>Java basiert</li>
							<li>GUI und CLI</li>
							<li>Skalierbar</li>
							<li>Plugins</li>
						</ul>
						<aside class="notes">
							Apache JMeter ist ein mÃ¤chtiges Open-Source-Tool, das vorwiegend fÃ¼r Performance-Tests und
							Lasttests von Anwendungen eingesetzt wird. Entwickelt in Java, bietet JMeter eine flexible
							Plattform fÃ¼r die Bewertung der Leistung von Webanwendungen.

							JMeter kann sowohl Ã¼ber eine grafische BenutzeroberflÃ¤che (GUI) als auch Ã¼ber die
							Kommandozeilenschnittstelle (CLI) bedient zu werden. WÃ¤hrend die GUI insbesondere wÃ¤hrend
							der
							Testentwicklungsphase fÃ¼r ihre Benutzerfreundlichkeit und visuelle RÃ¼ckmeldung geschÃ¤tzt
							wird,
							ermÃ¶glicht die CLI einen effizienteren Betrieb in Testumgebungen, was besonders bei der
							Integration in CI/CD-Pipelines nÃ¼tzlich ist. Oder eben auch fÃ¼r eine Integration in
							Cloud-LÃ¶sungen wie Azure Load Testing. Wir haben es auch in einer eigenen cloud-basierten
							LasttestlÃ¶sung im Einsatz, QLoad.

							JMeter zeichnet sich durch seine Skalierbarkeit aus. Es kann auf einzelnen Workstations fÃ¼r
							einfache Testaufgaben eingesetzt werden, lÃ¤sst sich aber auch in groÃŸem Umfang fÃ¼r komplexe
							Lasttests verwenden, die mehrere Server umfassen kÃ¶nnen. Diese Skalierbarkeit macht es zu
							einem
							idealen Werkzeug fÃ¼r Unternehmen jeder GrÃ¶ÃŸe, um die Leistung ihrer Anwendungen unter
							verschiedenen Lastbedingungen zu bewerten.

							Ein weiteres wichtiges Merkmal von JMeter sind die zahlreichen verfÃ¼gbaren Plugins, die
							seine
							FunktionalitÃ¤t erweitern. Diese Plugins ermÃ¶glichen es den Benutzern, neue TestfÃ¤higkeiten
							hinzuzufÃ¼gen, die Anpassung von Berichten zu verbessern und die Integration mit anderen
							Tools
							und Plattformen zu vereinfachen. Obwohl JMeter bereits eine umfassende Palette an
							TestmÃ¶glichkeiten bietet, erlauben es diese Plugins, das Tool noch weiter an spezifische
							BedÃ¼rfnisse anzupassen. Die Entwicklung eigener Plugins ist ebenfalls mÃ¶glich, was die
							FlexibilitÃ¤t von JMeter zusÃ¤tzlich erhÃ¶ht.

							Insgesamt bietet Apache JMeter als ein vielseitiges, leistungsstarkes Tool fÃ¼r
							Performance-Testing und Lasttest eine robuste LÃ¶sung fÃ¼r Entwickler und
							QualitÃ¤tssicherungs-Teams. Seine Open-Source-Natur, gepaart mit umfangreicher Dokumentation
							und
							einer aktiven Community, macht es zu einer zugÃ¤nglichen und wertvollen Ressource fÃ¼r die
							Optimierung der Leistung von Webanwendungen und anderen Diensten.
						</aside>
					</section>
				</section>
				<section>
					<h2>JMeter Skalieren âš–ï¸</h2>
					<img src="images/jmeter-controller-worker.png" class="r-stretch">
					<aside class="notes">
						(K6 angeblich 5 mio pro Minute von einer Maschine)
					</aside>
				</section>
				<section>
					<h2>â›… = ğŸ˜‡</h2>
					<aside class="notes">
						JMeter kann also genauso krass skalieren wie mein Testobjekt. super krass. 
						Ich fahre einen Tag fÃ¼r ein paar Stunden hunder Lastagenten hoch, fÃ¼hre JMeter darauf aus. Schicke mir dann am
						besten noch Ergebnisse in meine Zeitseriendatenbank wie prometheus oder influxdb. geil. Kosten Ã¼berschaubar.
						Das perfekte Cloud Projekt.
					</aside>
				</section>
				<section>
					<h2>â›ˆï¸ = ğŸ˜ˆ</h2>
					<aside class="notes">
						WÃ¤re der Teufel nicht ein fieses gemeines EichhÃ¶rnchen.
						Denn so einfach wie es theoretisch ist war es dann doch nicht. 
						Oder wie ein Professor mal zu mir meinte: "in der Theorie sind Theorie und Praxis dichter beieinander als in der Praxis".
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Testarchitektur I ğŸ—ï¸</h2>
				</section>
				<section data-background-color="white">
					<img src="images/arch1.png" class="r-stretch">
					<aside class="notes">
						Also was haben wir hier gemacht? Wir haben einfach ein System, was uns EC2 Instanzen in der AWS-Cloud zur verfÃ¼gung stellt.
						Oder eben vergleichbare bei anderen Cloud-Anbietern. Explizit aber keine Fargate Instantzen, denn die haben keine garantierten Netzwerkbandbreiten und sind 
						bei solchen Dimensionen an Tests unter UmstÃ¤nden nicht ausreichend schnell.
						Wir haben also eine Instanz, die uns die Lastagenten zur VerfÃ¼gung stellt. Und dann haben wir noch eine Instanz, die uns die Visualisierung zur VerfÃ¼gung stellt, alo Influx und Grafana.
						Dann brauch man noch ein MÃ¶glichkeit die JMeter Dateien auf alle Agents zu verteilen und startet JMeter einfach im Controller-worker-mode.
						Viel mehr ist es nicht. Das ist die Grundidee. Wie die Instanzen jetzt verknÃ¼pft sind, also in einem Kubernetes Cluter oder ob man das selbst managed, ist vÃ¶llig egal.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Fehlschlag ğŸª </h2>
					<ul class="fragment">
						<li>RAM, CPU, Netzwerk</li>
						<li>RAM stieg noch weiter an, wenn man zu wenig Netzwerk hatte</li>
						<li>Reporterstellung (mindestens x5)</li>
						<ul>
							<li>Nicht denken, dass es kaputt ist, es dauert nur ewig</li>
						</ul>
						<li>Grafana konnte nur noch 30 Sekunden Fenster laden</li>
						<li>Aber Zeitdruck</li>
					</ul>
					<aside class="notes">
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-16T14:27:42.853Z&to=2024-04-16T18:25:47.945Z&var-bucket=3-2-KommONE&var-hosts=$__all
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-21T22:00:00.000Z&to=2024-04-24T21:59:59.000Z&var-bucket=3-2-xl&var-hosts=$__all
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-23T07:25:44.162Z&to=2024-04-23T13:19:07.926Z&var-bucket=3-2-xxl&var-hosts=$__all
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-22T13:29:18.374Z&to=2024-04-22T14:16:11.560Z&var-bucket=3-2-xl&var-hosts=$__all

						------
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-02T15:33:17.987Z&to=2024-12-02T15:38:43.410Z&var-bucket=3-2-l&var-hosts=$__all&refresh=5s
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-02T15:48:08.702Z&to=2024-12-02T15:51:02.601Z&var-bucket=3-2-l&var-hosts=$__all&refresh=5s
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-02T16:25:22.202Z&to=2024-12-02T16:29:01.066Z&var-bucket=3-2-l&var-hosts=$__all&refresh=5s
						-----
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-03T12:22:50.417Z&to=2024-12-03T12:32:27.058Z&var-bucket=3-2-l&var-hosts=$__all&refresh=auto
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-03T12:34:19.307Z&to=2024-12-03T13:08:56.282Z&var-bucket=3-2-l&var-hosts=$__all&refresh=auto
					</aside>
				</section>
				<section><img src="images/run1.png" class="r-stretch"></section>
				<section>
					<h2>ğŸª²ğŸ</h2>
					<blockquote class="r-stretch">
						Note that while you can execute the JMeterEngine on your application server, you need to be
						mindful of the fact that this will be adding processing overhead on the application server and
						thus your testing results will be somewhat tainted. The recommended approach is to have one or
						more machines on the same Ethernet segment as your application server that you configure to run
						the JMeter Engine. This will minimize the impact of the network on the test results without
						impacting the performance of the application server itself.</blockquote>
				</section>
				<section>
					<blockquote class="r-stretch">However, remote mode does use more resources than running the same
						number of CLI mode tests independently. If many server instances are used, the client JMeter can
						become overloaded, as can the client network connection. [...] always check that your client is not overloaded.
					</blockquote>
				</section>
				<section>
					<h2>JMeter Master Config âš™ï¸</h2><img src="images/jmeter-master-config.png" class="r-stretch">
				</section>
			</section>
			<section>
				<section>
					<h2>Testarchitektur II ğŸ›ï¸ğŸ›•</h2>
				</section>
				<section>
					<h2>First things first</h2>
					<code>mehr RAM, mehr Netzwerkbandbreite</code>
					<aside class="notes">
						Was ist aufgefallen. TatsÃ¤chlich ist der RAM Verbrauch immer weiter angestiegen. Aber er ist unproportional angestiegen. NÃ¤mlich ab dem Zeitpunkt, an dem
						die Netzwerkbandbreite nicht mehr ausreichte. Scheinbar wird alles, was nicht verschickt werden kann, im RAM vorgehalten und fÃ¼hrt zu einer Explosion. 
						Ich hatte zunÃ¤chst nur versucht RAM zu erhÃ¶hen und bin gescheitert an massiven Problemen. Der verbrauch ging mit der LÃ¤nge des Tests immer weiter hoch.
						Erst als ich dann auch die Netzwerkbandbreite erhÃ¶ht habe, ging der RAM Verbrauch wieder runter.
						Deswegen hier erstmal die Empfehlung: mehr RAM und mehr Netzwerkbandbreite fÃ¼r den Controller. Und dann erst alles andere.
					</aside>
				</section>
				<section><img src="images/run2.png"></section>
				<section><img src="images/run3.png"></section>
				<section><img src="images/run-up-and-down.png" class="r-stretch"></section>
				<section>
					<img src="images/config-real.png">
					<aside class="notes">
						Hier habe ich es jetzt massiv Ã¼bertrieben. Aber better safe than sorry.
						Ob man am Ende fÃ¼r eine Instanz 1$ pro Stunde oder 5$ pro Stunde ausgibt, ist dann auch egal bei 3h Testlaufzeit.
					</aside>
				</section>
				<section data-background-color="white">
					<h2>ğŸ†•ğŸ†•ğŸ†•</h2>
					<img src="images/arch2.png" class="r-stretch">
					<aside class="notes">
						Ich stand ja noch vor meinem Grafana Problem. Ich konnte nicht mehr anstÃ¤ndig in die Daten schauen, weil es einfach zu viele waren. Das fetchen
						aus Influx war schon problematisch, die Aggregation dann zusÃ¤tzlich. Da kann man sicher noch was machen. 
						Aber ich stand eben auch unter Zeitdruck und habeeine andere einfache pragmatische lÃ¶sung gesucht und gefunden.
						
						QLoad + Jenkins
						Kann jeder, auch ohne cloud Kenntnisse
						Einfach agents starten und tests unabhÃ¤ngig laufen lassen
						Am ende reports einsammeln und gesamtreport erstellen.
					</aside>
				</section>
				<section data-visibility="hidden"><img src="images/run-real.png"></section>
				<section>
					<h2>StrippedBatch O.M.G. ğŸ˜±</h2>
					<code>mode=StrippedBatch</code>
					<aside class="notes">
						Tja und dann kam ein Zufallsfund. Nachdem ich einiges recherchiert hatte. 
						Wir hatten in unserem Setup eine alte JMeter Konfiguration. Mit dieser Konfiguration
						sammelte der JMeter Controller nicht nur Werte wie Status Code, Antwortzit usw., sondern auch
						den eigentlichen Inhalt der Antworten. Deswegen war der Controller so Ã¼berlastet.
						Er war die ganze Zeit damit beschÃ¤ftigt, die Antworten von den Workern zu sammeln und zu speichern.
						FÃ¼hlte sich im Nachgang etwas dÃ¤mlich an, dass ein einfaches boolean Flag in der konfig genau so EinProblem verursachen kann.
						Aber meistens sind die Antworten schon interessant. Gerade bei Fehlern wÃ¼rde man dann schon im Nachgangden eigentlichen Grund noch wissen wollen.
						Deswegen hatten wir diese option mit gutem Grund auch aktiviert. Aber in diesem Fall fÃ¼hrte es eben zum Overkill.
						Ohne den Modus, sah das ganze dann so aus.
					</aside>
				</section>
				<section>
					<code>mode=StrippedBatch</code>
					<img src="images/run-stripped.png" class="r-stretch">
					<aside class="notes">
						PlÃ¶tzlich ist es nicht mehr der Controller der Netzwerklast erzeugt, sondern nur noch die Worker.
						Und zwar in einem ertrÃ¤glichen VerhÃ¤ltnis.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Ergebnisse ğŸ“‰</h2>
				</section>
				<section>
					<h2>Grafana ğŸ“ˆ</h2>
					<img src="images/ergebnisse-grafana.png" class="r-stretch">
				</section>
				<section>
					<h2>Python ğŸ</h2>
					<img src="images/ergebnis.png" class="r-stretch">
					<aside class="notes">
						Nicht vorenthalten
						Ein Traum fÃ¼r jeden Performancetesterâ€¦zumindest fast:
					</aside>
				</section>
				<section>
					<img src="images/ergebnis2.png" class="r-stretch">
					<aside class="notes">
						am Ende hat mit Skalierung geklappt, und wir waren froh es ausprobiert zu haben. Aber es lief
						von Anfang an stabil, es gab nie Fehler.
					</aside>
				</section>
			</section>
			<section>
				<h2>LÃ¶sungsansÃ¤tze (mittel-/langfristig) â­</h2>
				<ul>
					<li>mehrere Systeme fÃ¼r Lastagenten</li>
					<li>Responses nicht im report speichern (StrippedBatch)</li>
					<li>Report asynchron laufen lassen</li>
					<li>Custom Listener der Responses nur im Fehlerfall speichert</li>
					<li>K6 statt JMeter (Kein Reporting, Kein Master-Slave; Aber ...)</li>
				</ul>
			</section>
			<section>
				<h2>Fazit ğŸ©»</h2>
				<ul>
					<li>Performance-Tests sind essenziell fÃ¼r die ZuverlÃ¤ssigkeit von Anwendungen.</li>
					<li>Apache JMeter ist ein mÃ¤chtiges Tool, aber nicht ohne Herausforderungen.</li>
					<li>Skalierung und Ressourcenmanagement sind kritische Faktoren.</li>
					<li>Cloud-basierte LÃ¶sungen bieten Potenzial, aber auch neue Probleme.</li>
					<li>Kontinuierliche Optimierung und Anpassung sind notwendig.</li>
				</ul>
			</section>
			<section>
				<h2>Vielen Dank! ğŸ™</h2>
				<img src="images/qr-code.png" class="r-stretch">
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/pointer/pointer.js"></script>
	<script src="plugin/zoom/zoom.js"></script>
	<script src="plugin/search/search.js"></script>
	<script>
		Reveal.initialize({
			pointer: {
				key: "q", // key to enable pointer, default "q", not case-sensitive
				color: "red", // color of a cursor, default "red" any valid CSS color
				opacity: 0.8, // opacity of cursor, default 0.8
				pointerSize: 30, // pointer size in px, default 12
				alwaysVisible: false, // should pointer mode be always visible? default "false"
				tailLength: 10, // NOT IMPLEMENTED YET!!! how long the "tail" should be? default 10
			},
			slideNumber: 'c/t',
			hash: true,
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealPointer, RevealZoom, RevealSearch]
		});
	</script>
</body>

</html>