<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>GTD2025</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/black.css">
	<link rel="stylesheet" href="plugin/pointer/pointer.css" />

	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section>
				<h2>Wenn Performancetest-Tools unter ihrer eigenen Last zusammenbrechen</h2>
				<p><img src="images/cover.png" style="width:40%"></p>
				<aside class="notes">
					Vielleicht seid ihr etwas überrascht über den Redner und das Thema. Ich habe gestern Nachmittag erfahren,
					dass ich als Ersatz einspringen kann. Und hier bin ich nun und freue mich, dass einige von euch hier sind, 
					um den Vortrag "Wenn Performancetest-Tools unter ihrer eigenen Last zusammenbrechen" zu hören.
					Die Vorbereitungszeit war jetzt nicht all zu lang. Ich versuche deswegen auch mehr auf praktische Erfahrungen einzugehen,
					statt es zu theoretisch zu gestalten. Angereichert mit der ein oder anderen Anekdote.
				</aside>
			</section>
			<section>
				<h2>Agenda 📋</h2>
				<ul>
					<li>kurze Vorstellung</li>
					<li>Testobjekt</li>
					<li>Performance-Testing</li>
					<li>Apache JMeter</li>
					<li>Test Setup & Durchführung</li>
					<li>Ergebnisse</li>
					<li>Fazit</li>
				</ul>
			</section>
			<section>
				<h2>Der Sprecher 🙊</h2><img src="images/matthias.png" class="r-stretch">
				<p>Matthias Eggert</p>
				<aside class="notes">
					Ich bin Matthias Eggert, 37 Jahre hier aus Frankfurt. Ich bin mittlerweile 12 Jahre professionell in der Softwareentwicklung tätig.
					Davon war ich 10 Jahre in der Automobilindustrie, hier bei Conti in Frankfurt Rödelheim und habe mich dort mit
					Developer-Plattformen beschäftigt. Das heißt, ich habe Software für Softwareentwickler entwickelt.
					Im Laufe der Zeit habe ich mich auf CI/CD und DevOps spezialisiert. Aus meiner DevOps-Rolle heraus bin ich dann bei
					Qytera gelandet, wo ich für Testautomatisierung, insbesondere von Performancetests zuständig bin.
				</aside>
			</section>
			<section>
				<section>
					<h2>Testobjekt 🧫</h2>
					<aside class="notes">
						Lasst uns doch direkt mal anschauen was eigentlich getestet wurde. Denn ohne das Testobjekt ist es
						ja auch schwer zu sagen, was wie warum getestet wurde.
					</aside>
				</section>
				<section>
					<h2>Demokratischer Prozess 🗽</h2>
					<ul>
						<li>Viele Millionen Menschen, Dienste und Crawler</li>
						<li>7-stellige Zahl von Requests pro Minute</li>
						<li>Und zwar in der Regel genau an einem Tag</li>
						<li>Auf unterschiedliche Endpunkte</li>
						<li>Große Responses</li>
					</ul>
					<aside class="notes">
						Es handelt sich um eine Webanwendung mit mehreren REST Schnittstellen, die öffentlich zugänglich ist.
						Die Webanwendung selbst ist für einen demokratischen Prozess zuständig, bei dem Millionen von Menschen
						und Diensten drauf zugreifen. Dabei reden für von mehreren zehn millionen Zugriffen pro Minute.
						Das ganze passiert in der Regel an einem Tag. Nicht davor und nicht dannach. In der Regel ist das bei uns ein Sonntag. 
						Die Anfragen gehen natürlich auf verschiedene Endpunkte. JSON Antworten und auch Dateiexporte.
					</aside>
				</section>
				<section data-background-color="white">
					<img src="images/halber-donut.png" class="r-stretch">
					<aside class="notes">
						Ich denke damit ist der krypische Teil der Erklärungen vorbei. Es geht um die Ergebnissanzeige der 
						Kommunahl- und Europawahlen 2024. Es handelte sich hierbei um einen behördlichen Auftrag, im Vorfeld
						zu den Wahlen die utzerlast entsprechend zu simulieren.
						Ich muss mich hier entschudligen. Hier ist ein bischen viel gelb zu sehen.
						 Die Grafik hab ich Ende November letzten Jahres bereits generieren lassen. Also durch ChatGPT. 
						 Und ChatGPT war in dem Moment noch nicht aktuell genug, und wusste nicht, dass die liberalen sich bereits selbst zerstört hatten.
					</aside>
				</section>
				<section data-background-color="white">
					<img src="images/donuts.png" class="r-stretch">
					<aside class="notes">
						Aber zurück zu den Wahlen. Wichtig dabei war, dass ein besonders hohes Wahlinteresse prognostiziert wurde. viele politische Turbulenzen, die wir alle kennen.
						Dazu natürlich der Umstand, dass mehrere Bundesländer parallel Kommunahlwahlen abhalten während ganz Europa noch wählt.
					</aside>
				</section>
				<section>
					<h2>Zurück zum Testobjekt 🗽</h2>
					<ul>
						<li>Viele Millionen Menschen, Dienste und Crawler</li>
						<li>7-stellige Zahl von Requests pro Minute</li>
						<li>Und zwar in der Regel genau an einem Tag</li>
						<li>Auf unterschiedliche Endpunkte</li>
						<li>Große Responses</li>
						<li>DDoS</li>
						<li>Angriffe aus dem Ausland</li>
					</ul>
					<aside class="notes">
						Jetzt muss man also sicherstellen, dass das System einen so großen Nutzerandrang standhalten kann, gleichzeitig aber 
						gegen DDos-Angriffe und mögliche Angriffe eines potentiellen Schurkenstaatees aus dem Ausland gewappnet ist.
						Aber schwenken wir mal rüber zu Performance testing.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Performance-Testing ⏱️</h2>
				</section>
				<section>
					<img src="images/chuck.png" alt="Chuck Norris" class="r-stretch">
					<h1 class="fragment">💩</h1>
					<aside class="notes">
						Natürlich könnte man jetzt sagen: "ach hat letzte mal geklappt, die paar mehr User die schaffen wir auch dieses mal". 
						frei nach dem Motto, testing is for wimps, ral men test in production. Kann man so machen, aber ist dann eben kacke. 
						Aber wir sind ja Tester, wir sind keine "echten kerle". Der gemeine Tester ist ja Grundsätzlich
						ängstlich und skeptisch. zu recht.
						Man stelle sich nur die Bild Schlagzeile vor: "Demokratie offline – Kein Signal am Wahltag", "Ampel-Koalition steht auf Rot – Wahlergebnisse im Blindflug" oder "Digitalisierung made in Germany".
						Nein wir sind wimps, wir wollen testen. was denn genau?
					</aside>
				</section>
				<section>
					<h2>Performance-Testing Arten 🏋️🧘🚣🏃</h2>
					<img src="images/performance-tests-types.png" alt="Performance-Testing Arten" class="r-stretch">
					<aside class="notes">
						Performance-Tests umfassen verschiedene Testarten, darunter Lasttests, Stress-Tests und
						Ausdauer- oder Dauertests. Jede dieser Testarten zielt darauf ab, unterschiedliche
						Leistungsaspekte einer Anwendung zu bewerten. Zum Beispiel:

						- Lasttests simulieren eine typische Nutzerbelastung, um zu sehen, wie die Anwendung unter
						normalen Bedingungen funktioniert.
						- Stress-Tests erhöhen die Belastung schrittweise über das normale Niveau hinaus, um die Grenzen
						der Anwendung zu finden.
						- Kapazitäts-Tests gehen mit Absicht über die Grenzen der Anwendung hinaus, um zu sehen, wie sie
						scheitert.
						- Ausdauer-Tests prüfen die Anwendung auf ihre Fähigkeit, über einen langen Zeitraum unter
						erwarteter Belastung zuverlässig zu funktionieren.

						Durch Performance-Tests können wir Engpässe identifizieren, die Leistung optimieren und
						sicherstellen, dass unsere Anwendung auch unter Spitzenlast oder bei steigender Nutzerzahl
						zuverlässig funktioniert. Mit diesem grundlegenden Verständnis von Performance-Tests können wir
						nun einen spezifischeren Blick auf Apache JMeter werfen und verstehen, wie es uns unterstützt,
						unsere Anwendungen zu testen.
					</aside>
				</section>
				<section>
					<h2>Auto-Scaling What 🚗🤔❓</h2>
					<img src="images/cloud.webp" class="r-stretch">
					<aside class="notes">
						Es gäbe ja noch tests wie Spike-Testing oder deutsch Lastspitzentests. Oder auch Skalierungstests. 
						Die wären durchaus wichtig wenn wir uns in einem dynamischen Umfeld bewegen würden wo die Nutzerzahlen ständig schwanken.
						Aber in unserem Fall ist das nicht so. Wir haben eine große Last an einem Tag, und dann ist es wieder ruhig.
						Entsprechend ist unser Testobjekt auch konstant groß dimensioniert. Es gibt kein Auto Scaling. Das ist ganz einfach überflüssig.
					</aside>
				</section>
				<section>
					<h2>Konstante Hochlast ↗️</h2>
					<img src="images/hochlast.png" alt="Performance-Testing Arten" class="r-stretch">
					<aside class="notes">
						Und weil das eben so ist, brauchen wir auch nur eine extrem hohe aber konstante Last zu erzeugen. Und das haben wior gemacht. 
						und zwar mit apache jmeter. in unserer eigenen kleinen Umgebung Namens Qload. Das hilft und Lastagenten in der Cloud zu erzeugen.
						Ich werde im folgenden allerdings eher auf die technischen details eingehen, wie man sowas umsetzen kann, als hieraus eine Werbeveranstaltung werden zu lassen.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<section>
						<h2>Apache JMeter 🪶</h2>
						<ul>
							<li><b>Open Source</b></li>
							<li>Java basiert</li>
							<li>GUI und CLI</li>
							<li>Skalierbar</li>
							<li>Plugins</li>
						</ul>
						<aside class="notes">
							Apache JMeter ist ein mächtiges Open-Source-Tool, das vorwiegend für Performance-Tests und
							Lasttests von Anwendungen eingesetzt wird. Entwickelt in Java, bietet JMeter eine flexible
							Plattform für die Bewertung der Leistung von Webanwendungen.

							JMeter kann sowohl über eine grafische Benutzeroberfläche (GUI) als auch über die
							Kommandozeilenschnittstelle (CLI) bedient zu werden. Während die GUI insbesondere während
							der
							Testentwicklungsphase für ihre Benutzerfreundlichkeit und visuelle Rückmeldung geschätzt
							wird,
							ermöglicht die CLI einen effizienteren Betrieb in Testumgebungen, was besonders bei der
							Integration in CI/CD-Pipelines nützlich ist. Oder eben auch für eine Integration in
							Cloud-Lösungen wie Azure Load Testing. Wir haben es auch in einer eigenen cloud-basierten
							Lasttestlösung im Einsatz, QLoad.

							JMeter zeichnet sich durch seine Skalierbarkeit aus. Es kann auf einzelnen Workstations für
							einfache Testaufgaben eingesetzt werden, lässt sich aber auch in großem Umfang für komplexe
							Lasttests verwenden, die mehrere Server umfassen können. Diese Skalierbarkeit macht es zu
							einem
							idealen Werkzeug für Unternehmen jeder Größe, um die Leistung ihrer Anwendungen unter
							verschiedenen Lastbedingungen zu bewerten.

							Ein weiteres wichtiges Merkmal von JMeter sind die zahlreichen verfügbaren Plugins, die
							seine
							Funktionalität erweitern. Diese Plugins ermöglichen es den Benutzern, neue Testfähigkeiten
							hinzuzufügen, die Anpassung von Berichten zu verbessern und die Integration mit anderen
							Tools
							und Plattformen zu vereinfachen. Obwohl JMeter bereits eine umfassende Palette an
							Testmöglichkeiten bietet, erlauben es diese Plugins, das Tool noch weiter an spezifische
							Bedürfnisse anzupassen. Die Entwicklung eigener Plugins ist ebenfalls möglich, was die
							Flexibilität von JMeter zusätzlich erhöht.

							Insgesamt bietet Apache JMeter als ein vielseitiges, leistungsstarkes Tool für
							Performance-Testing und Lasttest eine robuste Lösung für Entwickler und
							Qualitätssicherungs-Teams. Seine Open-Source-Natur, gepaart mit umfangreicher Dokumentation
							und
							einer aktiven Community, macht es zu einer zugänglichen und wertvollen Ressource für die
							Optimierung der Leistung von Webanwendungen und anderen Diensten.
						</aside>
					</section>
				</section>
				<section>
					<h2>JMeter Skalieren ⚖️</h2>
					<img src="images/jmeter-controller-worker.png" class="r-stretch">
					<aside class="notes">
						(K6 angeblich 5 mio pro Minute von einer Maschine)
					</aside>
				</section>
				<section>
					<h2>⛅ = 😇</h2>
					<aside class="notes">
						JMeter kann also genauso krass skalieren wie mein Testobjekt. super krass. 
						Ich fahre einen Tag für ein paar Stunden hunder Lastagenten hoch, führe JMeter darauf aus. Schicke mir dann am
						besten noch Ergebnisse in meine Zeitseriendatenbank wie prometheus oder influxdb. geil. Kosten überschaubar.
						Das perfekte Cloud Projekt.
					</aside>
				</section>
				<section>
					<h2>⛈️ = 😈</h2>
					<aside class="notes">
						Wäre der Teufel nicht ein fieses gemeines Eichhörnchen.
						Denn so einfach wie es theoretisch ist war es dann doch nicht. 
						Oder wie ein Professor mal zu mir meinte: "in der Theorie sind Theorie und Praxis dichter beieinander als in der Praxis".
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Testarchitektur I 🏗️</h2>
				</section>
				<section data-background-color="white">
					<img src="images/arch1.png" class="r-stretch">
					<aside class="notes">
						Also was haben wir hier gemacht? Wir haben einfach ein System, was uns EC2 Instanzen in der AWS-Cloud zur verfügung stellt.
						Oder eben vergleichbare bei anderen Cloud-Anbietern. Explizit aber keine Fargate Instantzen, denn die haben keine garantierten Netzwerkbandbreiten und sind 
						bei solchen Dimensionen an Tests unter Umständen nicht ausreichend schnell.
						Wir haben also eine Instanz, die uns die Lastagenten zur Verfügung stellt. Und dann haben wir noch eine Instanz, die uns die Visualisierung zur Verfügung stellt, alo Influx und Grafana.
						Dann brauch man noch ein Möglichkeit die JMeter Dateien auf alle Agents zu verteilen und startet JMeter einfach im Controller-worker-mode.
						Viel mehr ist es nicht. Das ist die Grundidee. Wie die Instanzen jetzt verknüpft sind, also in einem Kubernetes Cluter oder ob man das selbst managed, ist völlig egal.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Fehlschlag 🪠</h2>
					<ul class="fragment">
						<li>RAM, CPU, Netzwerk</li>
						<li>RAM stieg noch weiter an, wenn man zu wenig Netzwerk hatte</li>
						<li>Reporterstellung (mindestens x5)</li>
						<ul>
							<li>Nicht denken, dass es kaputt ist, es dauert nur ewig</li>
						</ul>
						<li>Grafana konnte nur noch 30 Sekunden Fenster laden</li>
						<li>Aber Zeitdruck</li>
					</ul>
					<aside class="notes">
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-16T14:27:42.853Z&to=2024-04-16T18:25:47.945Z&var-bucket=3-2-KommONE&var-hosts=$__all
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-21T22:00:00.000Z&to=2024-04-24T21:59:59.000Z&var-bucket=3-2-xl&var-hosts=$__all
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-23T07:25:44.162Z&to=2024-04-23T13:19:07.926Z&var-bucket=3-2-xxl&var-hosts=$__all
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-04-22T13:29:18.374Z&to=2024-04-22T14:16:11.560Z&var-bucket=3-2-xl&var-hosts=$__all

						------
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-02T15:33:17.987Z&to=2024-12-02T15:38:43.410Z&var-bucket=3-2-l&var-hosts=$__all&refresh=5s
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-02T15:48:08.702Z&to=2024-12-02T15:51:02.601Z&var-bucket=3-2-l&var-hosts=$__all&refresh=5s
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-02T16:25:22.202Z&to=2024-12-02T16:29:01.066Z&var-bucket=3-2-l&var-hosts=$__all&refresh=5s
						-----
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-03T12:22:50.417Z&to=2024-12-03T12:32:27.058Z&var-bucket=3-2-l&var-hosts=$__all&refresh=auto
						http://localhost:3000/d/PyR6xlG7z/system-monitoring-with-influxdb-cloud-and-telegraf?orgId=1&from=2024-12-03T12:34:19.307Z&to=2024-12-03T13:08:56.282Z&var-bucket=3-2-l&var-hosts=$__all&refresh=auto
					</aside>
				</section>
				<section><img src="images/run1.png" class="r-stretch"></section>
				<section>
					<h2>🪲🐞</h2>
					<blockquote class="r-stretch">
						Note that while you can execute the JMeterEngine on your application server, you need to be
						mindful of the fact that this will be adding processing overhead on the application server and
						thus your testing results will be somewhat tainted. The recommended approach is to have one or
						more machines on the same Ethernet segment as your application server that you configure to run
						the JMeter Engine. This will minimize the impact of the network on the test results without
						impacting the performance of the application server itself.</blockquote>
				</section>
				<section>
					<blockquote class="r-stretch">However, remote mode does use more resources than running the same
						number of CLI mode tests independently. If many server instances are used, the client JMeter can
						become overloaded, as can the client network connection. [...] always check that your client is not overloaded.
					</blockquote>
				</section>
				<section>
					<h2>JMeter Master Config ⚙️</h2><img src="images/jmeter-master-config.png" class="r-stretch">
				</section>
			</section>
			<section>
				<section>
					<h2>Testarchitektur II 🏛️🛕</h2>
				</section>
				<section>
					<h2>First things first</h2>
					<code>mehr RAM, mehr Netzwerkbandbreite</code>
					<aside class="notes">
						Was ist aufgefallen. Tatsächlich ist der RAM Verbrauch immer weiter angestiegen. Aber er ist unproportional angestiegen. Nämlich ab dem Zeitpunkt, an dem
						die Netzwerkbandbreite nicht mehr ausreichte. Scheinbar wird alles, was nicht verschickt werden kann, im RAM vorgehalten und führt zu einer Explosion. 
						Ich hatte zunächst nur versucht RAM zu erhöhen und bin gescheitert an massiven Problemen. Der verbrauch ging mit der Länge des Tests immer weiter hoch.
						Erst als ich dann auch die Netzwerkbandbreite erhöht habe, ging der RAM Verbrauch wieder runter.
						Deswegen hier erstmal die Empfehlung: mehr RAM und mehr Netzwerkbandbreite für den Controller. Und dann erst alles andere.
					</aside>
				</section>
				<section><img src="images/run2.png"></section>
				<section><img src="images/run3.png"></section>
				<section><img src="images/run-up-and-down.png" class="r-stretch"></section>
				<section>
					<img src="images/config-real.png">
					<aside class="notes">
						Hier habe ich es jetzt massiv übertrieben. Aber better safe than sorry.
						Ob man am Ende für eine Instanz 1$ pro Stunde oder 5$ pro Stunde ausgibt, ist dann auch egal bei 3h Testlaufzeit.
					</aside>
				</section>
				<section data-background-color="white">
					<h2>🆕🆕🆕</h2>
					<img src="images/arch2.png" class="r-stretch">
					<aside class="notes">
						Ich stand ja noch vor meinem Grafana Problem. Ich konnte nicht mehr anständig in die Daten schauen, weil es einfach zu viele waren. Das fetchen
						aus Influx war schon problematisch, die Aggregation dann zusätzlich. Da kann man sicher noch was machen. 
						Aber ich stand eben auch unter Zeitdruck und habeeine andere einfache pragmatische lösung gesucht und gefunden.
						
						QLoad + Jenkins
						Kann jeder, auch ohne cloud Kenntnisse
						Einfach agents starten und tests unabhängig laufen lassen
						Am ende reports einsammeln und gesamtreport erstellen.
					</aside>
				</section>
				<section data-visibility="hidden"><img src="images/run-real.png"></section>
				<section>
					<h2>StrippedBatch O.M.G. 😱</h2>
					<code>mode=StrippedBatch</code>
					<aside class="notes">
						Tja und dann kam ein Zufallsfund. Nachdem ich einiges recherchiert hatte. 
						Wir hatten in unserem Setup eine alte JMeter Konfiguration. Mit dieser Konfiguration
						sammelte der JMeter Controller nicht nur Werte wie Status Code, Antwortzit usw., sondern auch
						den eigentlichen Inhalt der Antworten. Deswegen war der Controller so überlastet.
						Er war die ganze Zeit damit beschäftigt, die Antworten von den Workern zu sammeln und zu speichern.
						Fühlte sich im Nachgang etwas dämlich an, dass ein einfaches boolean Flag in der konfig genau so EinProblem verursachen kann.
						Aber meistens sind die Antworten schon interessant. Gerade bei Fehlern würde man dann schon im Nachgangden eigentlichen Grund noch wissen wollen.
						Deswegen hatten wir diese option mit gutem Grund auch aktiviert. Aber in diesem Fall führte es eben zum Overkill.
						Ohne den Modus, sah das ganze dann so aus.
					</aside>
				</section>
				<section>
					<code>mode=StrippedBatch</code>
					<img src="images/run-stripped.png" class="r-stretch">
					<aside class="notes">
						Plötzlich ist es nicht mehr der Controller der Netzwerklast erzeugt, sondern nur noch die Worker.
						Und zwar in einem erträglichen Verhältnis.
					</aside>
				</section>
			</section>
			<section>
				<section>
					<h2>Ergebnisse 📉</h2>
				</section>
				<section>
					<h2>Grafana 📈</h2>
					<img src="images/ergebnisse-grafana.png" class="r-stretch">
				</section>
				<section>
					<h2>Python 🐍</h2>
					<img src="images/ergebnis.png" class="r-stretch">
					<aside class="notes">
						Nicht vorenthalten
						Ein Traum für jeden Performancetester…zumindest fast:
					</aside>
				</section>
				<section>
					<img src="images/ergebnis2.png" class="r-stretch">
					<aside class="notes">
						am Ende hat mit Skalierung geklappt, und wir waren froh es ausprobiert zu haben. Aber es lief
						von Anfang an stabil, es gab nie Fehler.
					</aside>
				</section>
			</section>
			<section>
				<h2>Lösungsansätze (mittel-/langfristig) ⭐</h2>
				<ul>
					<li>mehrere Systeme für Lastagenten</li>
					<li>Responses nicht im report speichern (StrippedBatch)</li>
					<li>Report asynchron laufen lassen</li>
					<li>Custom Listener der Responses nur im Fehlerfall speichert</li>
					<li>K6 statt JMeter (Kein Reporting, Kein Master-Slave; Aber ...)</li>
				</ul>
			</section>
			<section>
				<h2>Fazit 🩻</h2>
				<ul>
					<li>Performance-Tests sind essenziell für die Zuverlässigkeit von Anwendungen.</li>
					<li>Apache JMeter ist ein mächtiges Tool, aber nicht ohne Herausforderungen.</li>
					<li>Skalierung und Ressourcenmanagement sind kritische Faktoren.</li>
					<li>Cloud-basierte Lösungen bieten Potenzial, aber auch neue Probleme.</li>
					<li>Kontinuierliche Optimierung und Anpassung sind notwendig.</li>
				</ul>
			</section>
			<section>
				<h2>Vielen Dank! 🙏</h2>
				<img src="images/qr-code.png" class="r-stretch">
			</section>
		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/pointer/pointer.js"></script>
	<script src="plugin/zoom/zoom.js"></script>
	<script src="plugin/search/search.js"></script>
	<script>
		Reveal.initialize({
			pointer: {
				key: "q", // key to enable pointer, default "q", not case-sensitive
				color: "red", // color of a cursor, default "red" any valid CSS color
				opacity: 0.8, // opacity of cursor, default 0.8
				pointerSize: 30, // pointer size in px, default 12
				alwaysVisible: false, // should pointer mode be always visible? default "false"
				tailLength: 10, // NOT IMPLEMENTED YET!!! how long the "tail" should be? default 10
			},
			slideNumber: 'c/t',
			hash: true,
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealPointer, RevealZoom, RevealSearch]
		});
	</script>
</body>

</html>